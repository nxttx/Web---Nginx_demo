worker_processes 1; # the number of worker processes that will be spawned; can be compared to the number of cores in the system

events { worker_connections 1024; } # maximum number of simultaneous connections that can be opened by a worker process

http {
  proxy_read_timeout 300; # the amount of time a server will wait for a response from a client
  proxy_connect_timeout 300; # the amount of time a server will wait for a connection to be established with a client
  proxy_send_timeout 300; # the amount of time a server will wait for a response from a client when the server is sending data to the client

  # START Caching
    proxy_cache_path /etc/nginx/cache  # the path to the cache directory
    keys_zone=mycache:10m  # the name of the cache zone; the size of the cache zone in megabytes
    loader_threshold=300  # the number of requests that will be processed by the loader process 
    loader_files=200 # the number of files that will be processed by the loader process
    max_size=200m;  # the maximum size of the cache zone
  # END Caching

  # load balancer that randomly distributes requests to the upstream servers
  upstream app {
    # nothing; # Round-robin distribution; requests are distributed to the servers in turn
    # random; # random distribution; requests are distributed randomly
    # least_conn; # distribution based on the number of active connections; requests are distributed to the server with the least number of active connections
    # ip_hash; # distribution based on the client's IP address; requests from the same IP address are distributed to the same server

    server express; # the name or IP address of the upstream server express;
    server flask; # the name or IP address of the upstream server flask;
  }

  server {
    listen 80; # the port on which the server will listen for requests
    server_name localhost; # the name of the server; can be a domain name or an IP address ex: localhost, www.example.com,
    proxy_cache mycache; # the name of the cache zone

    location /api {
      proxy_pass http://app;

      # rewrite /api to / so that the app can handle the request
      rewrite ^/api/(.*)$ /$1 break;
    }

    location /api/time {
      proxy_pass http://app; # the upstream server to which the request will be forwarded
      proxy_cache mycache; # the name of the cache zone
      proxy_cache_valid 200 1m; # the amount of time the response will be cached; the response code; the amount of time the response will be cached

      # rewrite /api to / so that the app can handle the request
      rewrite ^/api/(.*)$ /$1 break;
    }

    # everything that is not /api/* is served from the static folder
    location / {
      root /usr/share/nginx/html;
      index index.html index.htm;
      try_files $uri $uri/ /index.html;
    }
  } 
}